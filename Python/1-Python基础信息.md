# Section-1 Python基础信息
## 1-爬虫是干什么的？
一个简单的 'https://www.baidu.com' 百度一下，源代码都是极其复杂，数据量极大的。
如果我们对于某些网站的一些特殊的数据有相应的需求：
> 例如:豆瓣前100高分的电影   
> 某些小说网站的耽美栏目下书单信息或者排行榜书单信息   
> 某音乐网站今日推荐音乐信息   
> 某政府网站的发布的年终数据   

需要爬取其中相应的一些数据，既不想一个个手打记录，但是又不想去研究这么复杂的代码。   
这个时候，Python-爬虫技术就可以排上大用处！

SUM1-结论：Python-爬虫技术可以自动化抓取网页上的信息！

**Python爬虫技术- 自动化抓取信息程序**

## 2-爬虫是怎样抓取数据的？
一件事情，知其然，更要知其所以然！  
学习很多时候，就是不断求知，不断探索的过程！
所以，言归正传，爬虫究竟是怎样爬取网页数据的呢？

**答案就是：模拟浏览器！**  

网络中有很多服务器，存储大量网页及数据，等待他人请求， 
爬虫就会伪装自己是浏览器，去向这些服务器请求数据，
大部分时候，这些服务器都会傻愣愣的直接把数据返还给爬虫，
如此这般，爬虫就得到了相应的数据，并按照我们的设定，将特定的数据归类存储展示！
> 服务器返回的数据格式有很多不同形式：HTML，json、、  
> 不同数据，可以使用不同的处理方法  
> 处理完成，就可以进行保存了！  
